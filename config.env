#!/usr/bin/env bash
# Default configuration
# shellcheck disable=all
# Project config values
PROJECT="Rosary In A Year (RIAY)"
# Turn on or turn off logging
LOGGING=false
# The year in which the podcasts are being followed
# This ensures that the day of the week is aligned with the year
YEAR=2025

# Github config values
REPO_OWNER=linusjf
REPO_NAME=RIAY

# overlay icon configuration
ICON_FILE="play-button.png"
ICON_SIZE="256x256"
ICON_OFFSET="+32+0"
ICON_COMMENT="Play Icon Added"

# add videos configuration
COMPACT_FILE="compact.txt"
VIDEOS_FILE="videos.txt"

# curl config values
# Time between successive requests to the LLM models
# This is to minimize triggering of rate limiting
GAP_BW_REQS=10
# Maximum number of retries for a REST API call
CURL_MAX_RETRIES=5
# The initial retry delay of 2 seconds which increases exponentially for each retry
CURL_INITIAL_RETRY_DELAY=2
# In curl, the --connect-timeout option sets how long (in seconds) to wait for the connection phase to the server to complete.
CURL_CONNECT_TIMEOUT=30
# --max-time in curl sets the maximum total time (in seconds) that the whole curl operation (connect + download/upload) is allowed to take.
CURL_MAX_TIME=90

# AI Config values
# The temperature value to be set for the LLM models
# Set it to zero to ensure reproducibility for a model
# Note that the summarizevideo script makes a best effort
# to ensure that summarization completes despite non-availability
# and/or request throttling by cycling through a list of
# free-tier Gemini models. All requests may not be made to the same model
# thus affecting reproducibility adversely.
# You can mitigate this either by specifying only one Gemini model
# which will meet all requests or using DeepSeek only.
# The script currently supports only these providers.
TEMPERATURE=0

GEMINI_MODELS=(
)
# The system prompt for summarizing text.
SYSTEM_SUMMARY_PROMPT="You are a helpful assistant that summarizes content. Be concise, helpful."
# The prompt for summarizing chunks within the podcast transcript.
CHUNK_SUMMARY_PROMPT="Summarize this text, excluding plugs, branding, and promotions. Avoid mention of Day, podcast and Rosary in a Day:"
# The prompt for the final summary of all the chunk summaries
FINAL_SUMMARY_PROMPT="Summarize the following text in the voice and style of C.S. Lewis, employing his clarity, moral insight, and rhetorical flair, as if writing directly to an intelligent but unassuming reader. Avoid modern jargon, maintain a tone of gentle conviction, and present the ideas as timeless truths. Do not include any meta-commentary, footnotes, or explanations—only the summary itself. Start with a level three markdown header and annotate it as 'AI-Generated Summary:' followed by your generated title (no colons, proper grammar)."
# The meta-prompt to generate image prompt and caption from the summary input
SUMMARY_IMAGE_META_PROMPT='You are an assistant that extracts visual meaning from text. Given any descriptive input, generate:
1. "image_prompt" – a detailed, visual description suitable for generating an image.
2. "caption" – a brief, expressive caption that summarizes or enhances the image concept.
Return your response as a JSON object in the format: {"caption": "This is the generated caption", "image_prompt": "This is the image prompt."}'

# list of files for generating README and readthedocs documentation
# in the order below
CONTENT_DOCS=(
  "RIAY=start.md"
  "January=January.md"
  "February=February.md"
  "March=March.md"
  "April=April.md"
  "May=May.md"
  "June=June.md"
  "July=July.md"
  "August=August.md"
  "September=September.md"
  "October=October.md"
  "November=November.md"
  "December=December.md"
)

# image generation inference model
IMAGE_GENERATION_MODEL="stabilityai/stable-diffusion-2-1"
