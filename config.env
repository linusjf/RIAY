#!/usr/bin/env bash
# Default configuration
# shellcheck disable=all
# Project config values
PROJECT="Rosary In A Year (RIAY)"
# Turn on or turn off logging
LOGGING=false
# The year in which the podcasts are being followed
# This ensures that the day of the week is aligned with the year
YEAR=2025

# Github config values
REPO_OWNER=linusjf
REPO_NAME=RIAY

# overlay icon configuration
ICON_FILE="play-button.png"
ICON_SIZE="256x256"
ICON_OFFSET="+32+0"
ICON_COMMENT="Play Icon Added"

# add videos configuration
COMPACT_FILE="compact.txt"
VIDEOS_FILE="videos.txt"

# curl config values
# Time between successive requests to the LLM models
# This is to minimize triggering of rate limiting
GAP_BW_REQS=0
# Maximum number of retries for a REST API call
CURL_MAX_RETRIES=5
# The initial retry delay of 2 seconds which increases exponentially for each retry
CURL_INITIAL_RETRY_DELAY=2
# In curl, the --connect-timeout option sets how long (in seconds) to wait for the connection phase to the server to complete.
CURL_CONNECT_TIMEOUT=30
# --max-time in curl sets the maximum total time (in seconds) that the whole curl operation (connect + download/upload) is allowed to take.
CURL_MAX_TIME=90

# Transcription config values
# whether to transcribe videos using a transcription service or rely on youtube auto-generated captions or creator provided subtitles
TRANSCRIBE_VIDEOS=false

# Automatic Speech Recognition (ASR) LLM config values
# ASR API KEY
ASR_LLM_API_KEY="$DEEPINFRA_TOKEN"
# ASR LLM base url
ASR_LLM_BASE_URL="https://api.deepinfra.com/v1"
# ASR LLM endpoint
# use translations end-point so that if in different language it is translated to English
ASR_LLM_ENDPOINT="/openai/audio/translations"
# ASR LLM model used for transcriptions and translations
ASR_LLM_MODEL="openai/whisper-large-v3"

# youtube config values
# number of retries for yt-dlp when downloading captions
YT_DLP_RETRIES=20
# time to wait in seconds before giving up
YT_DLP_SOCKET_TIMEOUT=30
# captions output directory
CAPTIONS_OUTPUT_DIR="captions"

# AI Config values
# The temperature value to be set for the LLM models
# Set it to zero to ensure reproducibility for a model
TEMPERATURE=0.5

# text llm api key
TEXT_LLM_API_KEY="$DEEPSEEK_API_KEY"
# text llm base url
TEXT_LLM_BASE_URL="https://api.deepseek.com"
# text llm chat model endpoint
TEXT_LLM_CHAT_ENDPOINT="/chat/completions"
# text llm model used for summarization
TEXT_LLM_MODEL="deepseek-chat"

# The system prompt for summarizing text.
SYSTEM_SUMMARY_PROMPT="You are a helpful assistant that summarizes content. Be concise, helpful."
# The prompt for summarizing chunks within the podcast transcript.
CHUNK_SUMMARY_PROMPT="Summarize this text, excluding plugs, branding, and promotions. Avoid mention of Day, podcast and Rosary in a Day:"
# The prompt for the final summary of all the chunk summaries
FINAL_SUMMARY_PROMPT="Summarize the following text in the voice and style of C.S. Lewis, employing his clarity, moral insight, and rhetorical flair, as if writing directly to an intelligent but unassuming reader. Generate a title as well. Avoid modern jargon, maintain a tone of gentle conviction, and present the ideas as timeless truths. Do not include any meta-commentary, footnotes, or explanations. Start with a level three markdown header
'### AI-Generated Summary: '. Append your generated title (no colons, proper grammar) to the header."
# The meta-prompt to generate image prompt and caption from the summary input
SUMMARY_IMAGE_META_PROMPT='You are an assistant that extracts visual meaning from text. Given any descriptive input, generate:
1. "image_prompt" – a detailed, visual description suitable for generating an image.
2. "caption" – a brief, expressive caption that summarizes or enhances the image concept. No colons.
Return your response as a JSON object in the format: {"caption": "This is the generated caption", "image_prompt": "This is the image prompt."}'

# list of files for generating README and readthedocs documentation
# in the order below
CONTENT_DOCS=(
  "RIAY=start.md"
  "January=January.md"
  "February=February.md"
  "March=March.md"
  "April=April.md"
  "May=May.md"
  "June=June.md"
  "July=July.md"
  "August=August.md"
  "September=September.md"
  "October=October.md"
  "November=November.md"
  "December=December.md"
)

# image generation configuration
# turn on or off image generation
AUTO_GENERATE_IMAGES=false
# relative path to image generation script passed just one parameter --- the prompt ---
# and writing the path of the jpeg image generated to stdout
# you can plug in your own script here if you wish to use a different image generation engine and/or provider
IMAGE_GENERATION_SCRIPT="openaigenerateimage"
# deepinfra image generation inference model
DEEPINFRA_IMAGE_GENERATION_MODEL="stabilityai/sd3.5"
# falai image generation inference model
FALAI_IMAGE_GENERATION_MODEL="janus"
